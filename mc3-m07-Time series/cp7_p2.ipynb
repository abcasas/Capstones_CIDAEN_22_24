{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/mCIDaeNnb.png\" alt=\"Logo CiDAEN\" align=\"right\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br><br><br>\n",
    "<h2><font color=\"#00586D\" size=4>Módulo 7</font></h2>\n",
    "\n",
    "\n",
    "\n",
    "<h1><font color=\"#00586D\" size=5>Capstone 7. Parte 2: Pronóstico de demanda eléctrica</font></h1>\n",
    "\n",
    "<br><br><br>\n",
    "<div style=\"text-align: right\">\n",
    "<font color=\"#00586D\" size=3>Enrique González, Luis de la Ossa</font><br>\n",
    "<font color=\"#00586D\" size=3>Máster en Ciencia de Datos e Ingeniería de Datos en la Nube I </font><br>\n",
    "<font color=\"#00586D\" size=3>Universidad de Castilla-La Mancha</font>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"indice\"></a>\n",
    "<h2><font color=\"#00586D\" size=5>Índice</font></h2>\n",
    "\n",
    "\n",
    "* [1. Creación del modelo de pronóstico](#section1)\n",
    "* [2. Ingesta y visualización del pronóstico](#section2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from influxdb_client import InfluxDBClient, Point, WritePrecision\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Optimiza los gráficos para pantalla retina\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "# Por defecto usamos el backend inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Oculta warnings\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# La libreta ocupa así el 95% de la pantalla\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente parte del capstone crearéis un modelo de pronóstico a partir de los datos ingestados en InfluxDB e añadiréis el pronóstico a un día vista de vuelta a InfluxDB de forma que en el sistema prototipado se pueda ver el pronóstico del día. Específicamente, para la creación del modelo utilizaréis los datos hasta el último día completo de datos y el pronóstico incluirá el dia siguiente (que podrá tener datos o no en nuestro sistema, pero que no los usaremos para entrenar). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"section1\"></a>\n",
    "## <font color=\"#00586D\"> 1. Creación del modelo de pronóstico</font>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la creación del modelo de pronóstico, necesitaremos descargarnos los datos de nuestra instancia para poder tener datos con los que entrenar. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#004D7F\"> <i class=\"fa fa-pencil-square-o\" aria-hidden=\"true\" style=\"color:#004D7F\"></i> Tarea 1</font>\n",
    "<br>\n",
    "\n",
    "Implementa la siguiente función que devuelve un DataFrame con todos los datos disponibles de demanda eléctrica almacenados en tu instancia de InfluxDB. Solo nos interesa la serie de demanda real, por lo que tendréis que filtrar el Forecast de red eléctrica usando Flux. \n",
    "\n",
    "Necesitaréis añadir la información de autenticación para vuestra instancia de InfluxDB a continuación. \n",
    "\n",
    "_Pista_: La práctica de InfluxDB que hicimos en este módulo os resultará útil para poder formar la consulta. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "token = \"mcidaen_token\"\n",
    "org = \"mcidaen\"\n",
    "bucket = \"capstone7\"\n",
    "\n",
    "client = InfluxDBClient(url=\"http://influxdb:8086\", token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_from_influxdb(client: InfluxDBClient, bucket: str, org: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Escribe el DataFrame en InfluxDB\n",
    "    \"\"\"\n",
    "    \n",
    "    ######## Solución: Guarda el resultado de la consulta en df\n",
    "\n",
    "    ###\n",
    "    \n",
    "    df_query = df.loc[:, ['_time', '_value']]\n",
    "    df_query['datetime'] = pd.to_datetime(df_query['_time'], utc=True).dt.tz_localize(None)\n",
    "    df_query['RealDemand'] = df_query['_value']\n",
    "    df_query = df_query[['datetime', 'RealDemand']]\n",
    "    df_query.index = df_query['datetime']\n",
    "    return df_query['RealDemand'].sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime\n",
       "2022-08-17 13:00:00    28558.083333\n",
       "2022-03-22 20:00:00    32101.333333\n",
       "2022-06-18 01:00:00    24592.250000\n",
       "2022-02-23 22:00:00    27416.500000\n",
       "2022-04-27 13:00:00    29158.500000\n",
       "2022-03-29 07:00:00    30680.500000\n",
       "2022-06-07 00:00:00    22885.583333\n",
       "2022-03-10 12:00:00    31206.666667\n",
       "2022-09-25 05:00:00    19363.166667\n",
       "2022-08-19 17:00:00    28068.416667\n",
       "2022-11-06 04:00:00    17734.416667\n",
       "2022-08-19 05:00:00    23990.666667\n",
       "2022-02-22 22:00:00    27137.000000\n",
       "2022-10-19 03:00:00    21814.916667\n",
       "2022-12-21 01:00:00    21955.166667\n",
       "2022-04-28 04:00:00    24237.833333\n",
       "2022-12-01 21:00:00    29663.833333\n",
       "2022-07-19 18:00:00    33729.666667\n",
       "2022-07-03 06:00:00    21313.833333\n",
       "2022-02-19 00:00:00    24770.666667\n",
       "Name: RealDemand, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_from_influxdb(client, bucket, org)\n",
    "df['2022'].sample(20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultado esperado:\n",
    "\n",
    "| datetime            |   RealDemand |\n",
    "|:--------------------|-------------:|\n",
    "| 2022-08-17 13:00:00 |      28558.1 |\n",
    "| 2022-03-22 20:00:00 |      32101.3 |\n",
    "| 2022-06-18 01:00:00 |      24592.2 |\n",
    "| 2022-02-23 22:00:00 |      27416.5 |\n",
    "| 2022-04-27 13:00:00 |      29158.5 |\n",
    "| 2022-03-29 07:00:00 |      30680.5 |\n",
    "| 2022-06-07 00:00:00 |      22885.6 |\n",
    "| 2022-03-10 12:00:00 |      31206.7 |\n",
    "| 2022-09-25 05:00:00 |      19363.2 |\n",
    "| 2022-08-19 17:00:00 |      28068.4 |\n",
    "| 2022-11-06 04:00:00 |      17734.4 |\n",
    "| 2022-08-19 05:00:00 |      23990.7 |\n",
    "| 2022-02-22 22:00:00 |      27137   |\n",
    "| 2022-10-19 03:00:00 |      21814.9 |\n",
    "| 2022-12-21 01:00:00 |      21955.2 |\n",
    "| 2022-04-28 04:00:00 |      24237.8 |\n",
    "| 2022-12-01 21:00:00 |      29663.8 |\n",
    "| 2022-07-19 18:00:00 |      33729.7 |\n",
    "| 2022-07-03 06:00:00 |      21313.8 |\n",
    "| 2022-02-19 00:00:00 |      24770.7 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"><font size=4> <i class=\"fa fa-check-square-o\" aria-hidden=\"true\" style=\"color:#00586D\"></i></font></div>\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con estos datos, el objetivo es crear un modelo de forecasting que nos permita pronosticar a un día vista la demanda de energía horaria. Aunque podéis usar el modelo que estiméis (siempre que funcione con el resto de componentes) en este caso hemos optado por crear un modelo de Prophet. \n",
    "\n",
    "Para facilitar su integración con el resto de código y poder ejecutar el modelo para pronosticar varios días, crearemos una función que entrene el modelo y realice un pronóstico para un conjunto de test. Para ello crearemos un modelo capaz de pronosticar, dado un histórico, la demanda de energía horaria del día siguiente al histórico. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#004D7F\"> <i class=\"fa fa-pencil-square-o\" aria-hidden=\"true\" style=\"color:#004D7F\"></i> Tarea 2</font>\n",
    "<br>\n",
    "\n",
    "Implementa la siguiente función que, dada la serie temporal de demanda anterior, _training_ y una lista de timestamps, _test_:\n",
    "- Entrena un modelo de Prophet con los datos de _training_\n",
    "- Pronostica las horas pasadas en _test_ \n",
    "\n",
    "Puedes asumir que el conjunto de datos tiene el formato de salida de la función de la tarea anterior.\n",
    "\n",
    "Opcional: Como trabajo opcional, puedes probar varios modelos de los expuestos durante el módulo para ver si puedes obtener un mejor resultado. Esto se tendrá en cuenta a la hora de evaluación del capstone. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from prophet import Prophet\n",
    "\n",
    "def train_forecast(training: pd.DataFrame, test: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Entrena con training y pronostica los datos de test\n",
    "    \"\"\"\n",
    "    \n",
    "    ######## Solución\n",
    "\n",
    "    #########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = list(pd.date_range(start=datetime.datetime(2023, 2, 24), freq='H', periods=24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:24:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:24:19 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "result = train_forecast(df[:datetime.datetime(2023, 2, 24)], test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime\n",
       "2023-02-24 00:00:00    26203.955169\n",
       "2023-02-24 01:00:00    25438.531198\n",
       "2023-02-24 02:00:00    25002.658036\n",
       "2023-02-24 03:00:00    25110.605144\n",
       "2023-02-24 04:00:00    26045.391911\n",
       "2023-02-24 05:00:00    27773.144263\n",
       "2023-02-24 06:00:00    29804.732413\n",
       "2023-02-24 07:00:00    31483.929592\n",
       "2023-02-24 08:00:00    32447.041337\n",
       "2023-02-24 09:00:00    32818.973247\n",
       "2023-02-24 10:00:00    32970.426706\n",
       "2023-02-24 11:00:00    33098.528803\n",
       "2023-02-24 12:00:00    33063.951347\n",
       "2023-02-24 13:00:00    32644.826011\n",
       "2023-02-24 14:00:00    31925.584272\n",
       "2023-02-24 15:00:00    31379.332628\n",
       "2023-02-24 16:00:00    31499.003632\n",
       "2023-02-24 17:00:00    32298.551500\n",
       "2023-02-24 18:00:00    33173.658905\n",
       "2023-02-24 19:00:00    33299.901735\n",
       "2023-02-24 20:00:00    32245.993259\n",
       "2023-02-24 21:00:00    30273.349091\n",
       "2023-02-24 22:00:00    28081.696255\n",
       "2023-02-24 23:00:00    26265.178496\n",
       "Name: yhat, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultado esperado (aprox.):\n",
    "    \n",
    "| datetime            |    yhat |\n",
    "|:--------------------|--------:|\n",
    "| 2023-02-24 00:00:00 | 26204   |\n",
    "| 2023-02-24 01:00:00 | 25438.5 |\n",
    "| 2023-02-24 02:00:00 | 25002.7 |\n",
    "| 2023-02-24 03:00:00 | 25110.6 |\n",
    "| 2023-02-24 04:00:00 | 26045.4 |\n",
    "| 2023-02-24 05:00:00 | 27773.1 |\n",
    "| 2023-02-24 06:00:00 | 29804.7 |\n",
    "| 2023-02-24 07:00:00 | 31483.9 |\n",
    "| 2023-02-24 08:00:00 | 32447   |\n",
    "| 2023-02-24 09:00:00 | 32819   |\n",
    "| 2023-02-24 10:00:00 | 32970.4 |\n",
    "| 2023-02-24 11:00:00 | 33098.5 |\n",
    "| 2023-02-24 12:00:00 | 33064   |\n",
    "| 2023-02-24 13:00:00 | 32644.8 |\n",
    "| 2023-02-24 14:00:00 | 31925.6 |\n",
    "| 2023-02-24 15:00:00 | 31379.3 |\n",
    "| 2023-02-24 16:00:00 | 31499   |\n",
    "| 2023-02-24 17:00:00 | 32298.6 |\n",
    "| 2023-02-24 18:00:00 | 33173.7 |\n",
    "| 2023-02-24 19:00:00 | 33299.9 |\n",
    "| 2023-02-24 20:00:00 | 32246   |\n",
    "| 2023-02-24 21:00:00 | 30273.3 |\n",
    "| 2023-02-24 22:00:00 | 28081.7 |\n",
    "| 2023-02-24 23:00:00 | 26265.2 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"><font size=4> <i class=\"fa fa-check-square-o\" aria-hidden=\"true\" style=\"color:#00586D\"></i></font></div>\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esta función ya podemos evaluar nuestro modelo. En este caso, debemos recordar que debemos evaluar nuestro modelo de forma diaria, ya que nuestro objetivo es hacer pronósticos a un día vista. Para ello podemos valernos de la función anterior y recorrer diariamente los valores de un conjunto de test, añadiendo en el training los valores hasta la fecha. Solo usaremos los primeros días del mes de enero para probar el método. Veamos como hacerlo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dates = list(pd.date_range(start=datetime.datetime(2023, 1, 1), end=datetime.datetime(2023, 1, 10), freq='D'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:29:43 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:29:50 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:29:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:29:56 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:29:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:30:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:30:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:30:10 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:30:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:30:16 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:30:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:30:22 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:30:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:30:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:30:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:30:36 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:30:36 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:30:43 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:30:43 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:30:49 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "maes = []\n",
    "for test_date in test_dates:\n",
    "    training = df[:test_date-datetime.timedelta(minutes=1)]\n",
    "    test = df[test_date:test_date+datetime.timedelta(days=1, minutes=-1)]\n",
    "    result = train_forecast(df, test.index)\n",
    "    r = mean_absolute_error(test, result)\n",
    "    maes.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2416.8888287164104"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(maes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este modelo ya podemos añadir la información de pronóstico como un nuevo campo en nuestra serie en InfluxDB. Para ello seguiremos la siguiente estrategia:\n",
    "- Nos centraremos solo en el último més de datos disponible. Para el último día, que posiblemente no estará completo, deberemos añadir las horas que falten. \n",
    "- Generaremos un pronóstico para cada día usando el modelo que creamos anteriormente. \n",
    "- Subiremos este pronóstico directamente a InfluxDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementaremos este proceso por partes a continuación. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#004D7F\"> <i class=\"fa fa-pencil-square-o\" aria-hidden=\"true\" style=\"color:#004D7F\"></i> Tarea 3 </font>\n",
    "<br>\n",
    "\n",
    "Implementa la siguiente función que, dada una fecha, devuelve una lista con los timestamps ordenados de sus horas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_hours(date: datetime.datetime) -> list :\n",
    "    ######## Solución\n",
    "    ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timestamp('2023-02-28 00:00:00', freq='H'),\n",
       " Timestamp('2023-02-28 01:00:00', freq='H'),\n",
       " Timestamp('2023-02-28 02:00:00', freq='H'),\n",
       " Timestamp('2023-02-28 03:00:00', freq='H'),\n",
       " Timestamp('2023-02-28 04:00:00', freq='H'),\n",
       " Timestamp('2023-02-28 05:00:00', freq='H'),\n",
       " Timestamp('2023-02-28 06:00:00', freq='H'),\n",
       " Timestamp('2023-02-28 07:00:00', freq='H'),\n",
       " Timestamp('2023-02-28 08:00:00', freq='H'),\n",
       " Timestamp('2023-02-28 09:00:00', freq='H'),\n",
       " Timestamp('2023-02-28 10:00:00', freq='H'),\n",
       " Timestamp('2023-02-28 11:00:00', freq='H'),\n",
       " Timestamp('2023-02-28 12:00:00', freq='H'),\n",
       " Timestamp('2023-02-28 13:00:00', freq='H'),\n",
       " Timestamp('2023-02-28 14:00:00', freq='H'),\n",
       " Timestamp('2023-02-28 15:00:00', freq='H'),\n",
       " Timestamp('2023-02-28 16:00:00', freq='H'),\n",
       " Timestamp('2023-02-28 17:00:00', freq='H'),\n",
       " Timestamp('2023-02-28 18:00:00', freq='H'),\n",
       " Timestamp('2023-02-28 19:00:00', freq='H'),\n",
       " Timestamp('2023-02-28 20:00:00', freq='H'),\n",
       " Timestamp('2023-02-28 21:00:00', freq='H'),\n",
       " Timestamp('2023-02-28 22:00:00', freq='H'),\n",
       " Timestamp('2023-02-28 23:00:00', freq='H')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_hours(datetime.datetime(2023, 2, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resutado esperado:\n",
    "```\n",
    "[Timestamp('2023-02-28 00:00:00', freq='H'),\n",
    " Timestamp('2023-02-28 01:00:00', freq='H'),\n",
    " Timestamp('2023-02-28 02:00:00', freq='H'),\n",
    " Timestamp('2023-02-28 03:00:00', freq='H'),\n",
    " Timestamp('2023-02-28 04:00:00', freq='H'),\n",
    " Timestamp('2023-02-28 05:00:00', freq='H'),\n",
    " Timestamp('2023-02-28 06:00:00', freq='H'),\n",
    " Timestamp('2023-02-28 07:00:00', freq='H'),\n",
    " Timestamp('2023-02-28 08:00:00', freq='H'),\n",
    " Timestamp('2023-02-28 09:00:00', freq='H'),\n",
    " Timestamp('2023-02-28 10:00:00', freq='H'),\n",
    " Timestamp('2023-02-28 11:00:00', freq='H'),\n",
    " Timestamp('2023-02-28 12:00:00', freq='H'),\n",
    " Timestamp('2023-02-28 13:00:00', freq='H'),\n",
    " Timestamp('2023-02-28 14:00:00', freq='H'),\n",
    " Timestamp('2023-02-28 15:00:00', freq='H'),\n",
    " Timestamp('2023-02-28 16:00:00', freq='H'),\n",
    " Timestamp('2023-02-28 17:00:00', freq='H'),\n",
    " Timestamp('2023-02-28 18:00:00', freq='H'),\n",
    " Timestamp('2023-02-28 19:00:00', freq='H'),\n",
    " Timestamp('2023-02-28 20:00:00', freq='H'),\n",
    " Timestamp('2023-02-28 21:00:00', freq='H'),\n",
    " Timestamp('2023-02-28 22:00:00', freq='H'),\n",
    " Timestamp('2023-02-28 23:00:00', freq='H')]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"><font size=4> <i class=\"fa fa-check-square-o\" aria-hidden=\"true\" style=\"color:#00586D\"></i></font></div>\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ingestar el pronóstico en InfluxDB, podemos usar la siguiente función, similar a la función que utilizásteis en la primera práctica y que básicamente toma el pronóstico del modelo de Prophet y lo ingesta usando la API de escritura de InfluxDB. El pronóstico se ingestará en la misma medida que la demanda, pero con el campo `CP7Forecast`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_to_influxdb(df: pd.DataFrame, client: InfluxDBClient, bucket: str, org: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Escribe el pronóstico en InfluxDB\n",
    "    \"\"\"\n",
    "    df = df.reset_index()\n",
    "    df['time'] = df['datetime']\n",
    "    df['CP7Forecast'] = df['yhat']\n",
    "    to_write = df[['time', 'CP7Forecast']]\n",
    "    to_write = to_write.set_index('time')[['CP7Forecast']]\n",
    "    write_api = client.write_api(write_options=SYNCHRONOUS)\n",
    "    write_api.write(bucket, org, record=to_write, data_frame_measurement_name='demand')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con estas funciones ya tenemos todo lo necesario para poder escribir en InfluxDB los datos de pronóstico. Para ello, partiendo de un día inicial desde el que empezaremos a generar pronósticos, usaremos una estrategia similar al método de evaluación anterior, simplemente teniendo en cuenta que generaremos nosotros las horas en vez de usar las que aparecen en un conjunto de test. A continuación mostramos como ingestar los resultados a partir de un día determinado. Podéis ejecutar el código a continuación para añadir el pronóstico a vuestra instancia de InfluxDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2023-02-22', '2023-02-23', '2023-02-24', '2023-02-25',\n",
       "               '2023-02-26'],\n",
       "              dtype='datetime64[ns]', freq='D')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "begin = datetime.datetime(2023, 2, 22)\n",
    "dates_to_ingest = pd.date_range(start=begin, end=datetime.datetime.now().date(), freq='D')\n",
    "dates_to_ingest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingesting for date: 2023-02-22 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:31:33 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:31:39 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingesting for date: 2023-02-23 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:31:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:31:45 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingesting for date: 2023-02-24 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:31:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:31:51 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingesting for date: 2023-02-25 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:31:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:31:58 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingesting for date: 2023-02-26 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:31:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:32:05 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "for dt in dates_to_ingest:\n",
    "    hours = get_hours(dt)\n",
    "    print(f\"Ingesting for date: {dt}\")\n",
    "    training = df[:dt-datetime.timedelta(minutes=1)]\n",
    "    result = train_forecast(df, hours)\n",
    "    save_to_influxdb(result, client, bucket, org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando acabe el proceso anterior ya deberíais tener los resultados en InfluxDB. Solo quedaría adaptar el dashboard anterior para visualizar también los datos de pronóstico. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#004D7F\"> <i class=\"fa fa-pencil-square-o\" aria-hidden=\"true\" style=\"color:#004D7F\"></i> Tarea 4</font>\n",
    "<br>\n",
    "\n",
    "Añade a la celda tipo graph del dashboard que creaste en la primera parte del capstone la serie predicha por el modelo que hemos entrenado.\n",
    "\n",
    "Para visualizar el pronóstico a futuro, necesitarás modificar el filtro de tiempo para incluir el día en curso. \n",
    "\n",
    "**Añade una captura de tu dashboard a continuación (incluyéndo el dashboard con la entrega)**. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultado esperado (aprox):\n",
    "\n",
    "![tarea4](img/p2tarea4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"><font size=4> <i class=\"fa fa-check-square-o\" aria-hidden=\"true\" style=\"color:#00586D\"></i></font></div>\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
